{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VV0wf356wGfA"
      },
      "source": [
        "**Audio Restoration for Generative Models — Improving MusicGen Outputs**\n",
        "\n",
        "*Giada Manfredi*\n",
        "\n",
        "January 2026"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYD34CHpUaqT",
        "outputId": "54152878-f6ab-4252-df7e-77280f50b090"
      },
      "outputs": [],
      "source": [
        "!pip install noisereduce\n",
        "!pip install pedalboard\n",
        "!pip install librosa\n",
        "!pip install demucs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VVfIf99SUb6s"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "import os\n",
        "from pedalboard.io import AudioFile\n",
        "from pedalboard import *\n",
        "import noisereduce as nr\n",
        "import soundfile as sf\n",
        "from IPython.display import Audio, display\n",
        "import matplotlib.pyplot as plt\n",
        "from demucs import pretrained\n",
        "from demucs.apply import apply_model\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "5Xb-JUjZVKLs",
        "outputId": "e35e0310-e1fb-4556-c8ff-59f26d32e1dd"
      },
      "outputs": [],
      "source": [
        "# 1. CARICAMENTO AUDIO\n",
        "\n",
        "# Messaggio iniziale per invitare l'utente a caricare un file audio\n",
        "print(\"Carica il tuo file audio.\")\n",
        "\n",
        "# Caricamento del file tramite l'interfaccia di upload di Colab\n",
        "uploaded = files.upload()\n",
        "\n",
        "if uploaded:\n",
        "    for fn in uploaded.keys():\n",
        "        audio_file_path = f\"/content/{fn}\"\n",
        "        print(f\"File '{fn}' caricato.\")\n",
        "\n",
        "        try:\n",
        "            # Carica il file audio con librosa\n",
        "            # sr=None significa che viene mantenuta la frequenza di campionamento originale\n",
        "            # y contiene i dati audio, sr contiene la frequenza di campionamento\n",
        "            y, sr = librosa.load(audio_file_path, sr=None)\n",
        "\n",
        "            print(f\"File audio caricato con successo: {audio_file_path}\")\n",
        "            print(f\"Frequenza di campionamento (sr): {sr} Hz\")\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Errore: Il file '{audio_file_path}' non è stato trovato. Controlla il percorso.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Si è verificato un errore durante il caricamento del file audio: {e}\")\n",
        "else:\n",
        "    print(\"Nessun file selezionato.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwQpLI3WVjUF",
        "outputId": "ff73104d-1822-464a-b0b7-9f46272220c3"
      },
      "outputs": [],
      "source": [
        "# 2. RESTAURAZIONE AUDIO DIRETTA\n",
        "\n",
        "# Frequenza di campionamento target\n",
        "target_sr = 44100  # Hz\n",
        "\n",
        "# Controlla se è necessario ricampionare l'audio\n",
        "if sr != target_sr:\n",
        "    print(f\"Ricampionamento dell'audio da {sr} Hz a {target_sr} Hz.\")\n",
        "    audio_to_process = librosa.resample(y=y, orig_sr=sr, target_sr=target_sr)\n",
        "    current_sr = target_sr\n",
        "else:\n",
        "    audio_to_process = y\n",
        "    current_sr = sr\n",
        "\n",
        "# Riduzione del rumore\n",
        "# stationary=True indica che il rumore è costante nel tempo\n",
        "# prop_decrease=0.75 controlla di quanto ridurre il rumore\n",
        "reduced_noise = nr.reduce_noise(y=audio_to_process, sr=current_sr, stationary=True, prop_decrease=0.75)\n",
        "\n",
        "# Creazione della catena di effetti tramite Pedalboard\n",
        "# NoiseGate: elimina i suoni al di sotto di una certa soglia\n",
        "# Compressor: uniforma il volume dell'audio\n",
        "# LowShelfFilter: aumenta le frequenze basse (bassi)\n",
        "# Gain: aumenta il volume complessivo\n",
        "board = Pedalboard([\n",
        "    NoiseGate(threshold_db=-30, ratio=1.5, release_ms=250),\n",
        "    Compressor(threshold_db=-16, ratio=4),\n",
        "    LowShelfFilter(cutoff_frequency_hz=400, gain_db=10, q=1),\n",
        "    Gain(gain_db=2)\n",
        "])\n",
        "\n",
        "# Applica gli effetti all'audio ridotto dal rumore\n",
        "effected_audio = board(reduced_noise, current_sr)\n",
        "\n",
        "# Salvataggio dell'audio restaurato\n",
        "num_channels0 = 1 if len(effected_audio.shape) == 1 else effected_audio.shape[0]\n",
        "output_filename_pedalboard = '/content/audio_enhenced.wav'\n",
        "\n",
        "with AudioFile(output_filename_pedalboard, 'w', current_sr, num_channels=num_channels0) as f:\n",
        "    f.write(effected_audio)\n",
        "\n",
        "print(f\"Audio elaborato e salvato come '{output_filename_pedalboard}'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxCGP3ixY6Xy",
        "outputId": "2e055b47-6442-4ce2-9e55-5cac3d18cfb4"
      },
      "outputs": [],
      "source": [
        "# 3. RESTAURAZIONE AUDIO STEM-WISE\n",
        "\n",
        "print(\"Caricamento modello Demucs...\")\n",
        "# Carica il modello pre-addestrato per la separazione delle tracce\n",
        "model = pretrained.get_model('mdx')\n",
        "\n",
        "# Per MDX è necessario un audio stereo\n",
        "# Convertiamo l'audio in tensor PyTorch\n",
        "audio_tensor = torch.tensor(audio_to_process, dtype=torch.float32)\n",
        "audio_tensor = audio_tensor.unsqueeze(0).unsqueeze(0)  # Shape: (1,1,N)\n",
        "audio_tensor = audio_tensor.repeat(1, 2, 1)            # Shape: (1,2,N), duplicando i canali per stereo\n",
        "\n",
        "print(\"Separazione in tracce...\")\n",
        "with torch.no_grad():\n",
        "    # Applica il modello Demucs\n",
        "    # shifts: 0, split: True, overlap: 0.0, transition_power: 1.0\n",
        "    # Output atteso: (batch, num_sources, num_channels, num_samples)\n",
        "    demucs_output = apply_model(\n",
        "        model,\n",
        "        audio_tensor,\n",
        "        0,      # shifts\n",
        "        True,   # split\n",
        "        0.0,    # overlap\n",
        "        1.0     # transition_power\n",
        "    )\n",
        "\n",
        "# Rimuove le dimensioni di lunghezza 1 (batch)\n",
        "# Risultato atteso: (num_sources, num_channels, num_samples)\n",
        "separated_sources_processed = demucs_output.squeeze()\n",
        "\n",
        "# Crea la cartella per salvare le tracce separate\n",
        "output_dir = \"/content/separated_tracks\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Salva ogni traccia separata\n",
        "for i, name in enumerate(model.sources):\n",
        "    src_tensor = separated_sources_processed[i]  # (num_channels, num_samples)\n",
        "\n",
        "    # Controllo aggiuntivo per eventuali dimensioni extra inattese\n",
        "    if src_tensor.ndim > 2:\n",
        "        src_tensor = src_tensor[0]  # Prende la prima dimensione extra\n",
        "\n",
        "    # Trasponi per soundfile.write: (num_samples, num_channels)\n",
        "    src = src_tensor.cpu().numpy().T\n",
        "    sf.write(os.path.join(output_dir, f\"{name}.wav\"), src, current_sr)\n",
        "\n",
        "print(\"Separazione completata.\")\n",
        "\n",
        "# Cartelle per le tracce pulite\n",
        "input_dir = \"/content/separated_tracks\"\n",
        "output_dir = \"/content/cleaned_separated_tracks\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "cleaned_tracks_data = []\n",
        "\n",
        "# Lista dei file audio separati\n",
        "audio_files = [f for f in os.listdir(input_dir) if f.endswith('.wav')]\n",
        "\n",
        "# Ciclo di pulizia e restauro di ogni traccia\n",
        "for filename in audio_files:\n",
        "    track_path = os.path.join(input_dir, filename)\n",
        "    track_name = os.path.splitext(filename)[0]\n",
        "\n",
        "    print(f\"Processando: {track_name}\")\n",
        "\n",
        "    # Carica la traccia\n",
        "    y_track, sr_track = librosa.load(track_path, sr=current_sr, mono=False)\n",
        "\n",
        "    # Se stereo, converte in mono mediando i canali\n",
        "    if y_track.ndim > 1:\n",
        "        if y_track.shape[0] == 2:\n",
        "            y_track_mono = y_track.mean(axis=0)\n",
        "        else:\n",
        "            y_track_mono = y_track[0]\n",
        "    else:\n",
        "        y_track_mono = y_track\n",
        "\n",
        "    # Riduzione del rumore\n",
        "    reduced_noise_track = nr.reduce_noise(\n",
        "        y=y_track_mono,\n",
        "        sr=sr_track,\n",
        "        stationary=True,\n",
        "        prop_decrease=0.75\n",
        "    )\n",
        "\n",
        "    # Applicazione della catena di effetti\n",
        "    board = Pedalboard([\n",
        "        NoiseGate(threshold_db=-30, ratio=1.5, release_ms=250),\n",
        "        Compressor(threshold_db=-16, ratio=4),\n",
        "        LowShelfFilter(cutoff_frequency_hz=400, gain_db=10, q=1),\n",
        "        Gain(gain_db=2)\n",
        "    ])\n",
        "\n",
        "    effected_audio_track = board(reduced_noise_track, sr_track)\n",
        "\n",
        "    # Salva i dati della traccia pulita in memoria\n",
        "    cleaned_tracks_data.append({\n",
        "        'name': track_name,\n",
        "        'audio': effected_audio_track,\n",
        "        'sr': sr_track\n",
        "    })\n",
        "    print(f\"Finito di processare {track_name}.\")\n",
        "\n",
        "print(\"Tutte le tracce sono restaurate.\")\n",
        "\n",
        "# Salvataggio delle tracce restaurate\n",
        "print(\"Salvando le tracce restaurate...\")\n",
        "for track_data in cleaned_tracks_data:\n",
        "    track_name = track_data['name']\n",
        "    audio_data = track_data['audio']\n",
        "    sample_rate = track_data['sr']\n",
        "\n",
        "    output_filepath = os.path.join(output_dir, f\"{track_name}_cleaned.wav\")\n",
        "\n",
        "    with AudioFile(output_filepath, 'w', sample_rate, num_channels=1) as f:\n",
        "        f.write(audio_data)\n",
        "\n",
        "    print(f\"Traccia restaurata salvata: {output_filepath}\")\n",
        "\n",
        "print(\"Tutte le tracce restaurate sono state salvate.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        },
        "id": "NZ-icU4obz2K",
        "outputId": "5237e0de-a13f-499b-c6c0-522d249b25a3"
      },
      "outputs": [],
      "source": [
        "# 4. CARICAMENTO E RIPRODUZIONE DELLE TARCCE ORIGINALI E RESTAURATE\n",
        "\n",
        "original_tracks_data = []\n",
        "\n",
        "# Cartella delle tracce originali separate (creata nel passo precedente)\n",
        "input_dir_original = \"/content/separated_tracks\"\n",
        "\n",
        "# Verifica che current_sr sia definito\n",
        "if 'current_sr' not in locals():\n",
        "    print(\"Attenzione: current_sr non trovato. Impostato a 44100 Hz di default.\")\n",
        "    current_sr = 44100\n",
        "\n",
        "# Caricamento delle tracce originali\n",
        "for filename in os.listdir(input_dir_original):\n",
        "    if filename.endswith('.wav'):\n",
        "        track_path = os.path.join(input_dir_original, filename)\n",
        "        track_name = os.path.splitext(filename)[0]\n",
        "\n",
        "        # Carica la traccia senza ricampionamento (stereo se presente)\n",
        "        y_track, sr_track = librosa.load(track_path, sr=current_sr, mono=False)\n",
        "\n",
        "        # Se la traccia è stereo, converte in mono per una riproduzione coerente\n",
        "        if y_track.ndim > 1 and y_track.shape[0] == 2:\n",
        "            y_track_mono = y_track.mean(axis=0)\n",
        "        else:\n",
        "            y_track_mono = y_track  # già mono o canale singolo\n",
        "\n",
        "        # Aggiunge la traccia ai dati originali\n",
        "        original_tracks_data.append({\n",
        "            'name': track_name,\n",
        "            'audio': y_track_mono,\n",
        "            'sr': sr_track\n",
        "        })\n",
        "\n",
        "# Riproduzione delle tracce originali\n",
        "print(\"Riproduzione delle tracce originali:\")\n",
        "for track_data in original_tracks_data:\n",
        "    track_name = track_data['name']\n",
        "    audio_data = track_data['audio']\n",
        "    sample_rate = track_data['sr']\n",
        "    print(f\"Riproduzione della traccia originale: {track_name}\")\n",
        "    display(Audio(audio_data, rate=sample_rate))\n",
        "\n",
        "# Riproduzione delle tracce restaurate\n",
        "print(\"Riproduzione delle tracce restaurate:\")\n",
        "for track_data in cleaned_tracks_data:\n",
        "    track_name = track_data['name']\n",
        "    audio_data = track_data['audio']\n",
        "    sample_rate = track_data['sr']\n",
        "    print(f\"Riproduzione della traccia restaurata: {track_name}\")\n",
        "    display(Audio(audio_data, rate=sample_rate))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IZ_O-dadc9a7",
        "outputId": "4ba88acd-1108-4e01-98de-3395132480e7"
      },
      "outputs": [],
      "source": [
        "# 5. CONFRONTO DEGLI SPETTROGRAMMI DELLE TRACCE ORIGINALI E RESTAURATE\n",
        "\n",
        "print(\"Confronto fra gli spettrogrammi delle tracce originali e restaurate\")\n",
        "\n",
        "all_spectrograms_db_data = []  # Memorizza tutti gli spettrogrammi in dB\n",
        "min_db_values = []  # Per calcolare il minimo globale (scala colore uniforme)\n",
        "max_db_values = []  # Per calcolare il massimo globale (scala colore uniforme)\n",
        "\n",
        "# -------------------------\n",
        "# Elaborazione delle tracce originali (ora chiamate input)\n",
        "# -------------------------\n",
        "for track_data in original_tracks_data:\n",
        "    y_track = track_data['audio']\n",
        "    sr_track = track_data['sr']\n",
        "    track_name = track_data['name']\n",
        "\n",
        "    # Calcola lo spettrogramma di Mel\n",
        "    S = librosa.feature.melspectrogram(y=y_track, sr=sr_track)\n",
        "    S_db = librosa.power_to_db(S, ref=np.max)  # Converte in decibel\n",
        "\n",
        "    # Etichetta: nome traccia fra virgolette + tipo \"input\" alla fine\n",
        "    display_name = f'\"{track_name}\" input'\n",
        "\n",
        "    all_spectrograms_db_data.append({\n",
        "        'name': display_name,\n",
        "        'spectrogram_db': S_db,\n",
        "        'sr': sr_track\n",
        "    })\n",
        "\n",
        "    min_db_values.append(S_db.min())\n",
        "    max_db_values.append(S_db.max())\n",
        "\n",
        "# -------------------------\n",
        "# Elaborazione delle tracce pulite (ora chiamate restored)\n",
        "# -------------------------\n",
        "for track_data in cleaned_tracks_data:\n",
        "    y_track = track_data['audio']\n",
        "    sr_track = track_data['sr']\n",
        "    track_name = track_data['name']\n",
        "\n",
        "    S = librosa.feature.melspectrogram(y=y_track, sr=sr_track)\n",
        "    S_db = librosa.power_to_db(S, ref=np.max)\n",
        "\n",
        "    # Etichetta: nome traccia fra virgolette + tipo \"restored\" alla fine\n",
        "    display_name = f'\"{track_name}\" restored'\n",
        "\n",
        "    all_spectrograms_db_data.append({\n",
        "        'name': display_name,\n",
        "        'spectrogram_db': S_db,\n",
        "        'sr': sr_track\n",
        "    })\n",
        "\n",
        "    min_db_values.append(S_db.min())\n",
        "    max_db_values.append(S_db.max())\n",
        "\n",
        "# Calcola min e max globali per la scala dei colori uniforme tra tutte le tracce\n",
        "global_vmin = np.min(min_db_values)\n",
        "global_vmax = np.max(max_db_values)\n",
        "\n",
        "# Elenco dei nomi delle tracce senza distinzione input/restored\n",
        "unique_track_names = [data['name'].replace('\"', '').replace(' input', '').replace(' restored', '')\n",
        "                      for data in all_spectrograms_db_data]\n",
        "unique_track_names = sorted(list(set(unique_track_names)))\n",
        "\n",
        "# Inizializza la figura con righe = numero di tracce, 2 colonne (input | restored)\n",
        "fig, axes = plt.subplots(nrows=len(unique_track_names), ncols=2,\n",
        "                         figsize=(15, 5 * len(unique_track_names)))\n",
        "\n",
        "# Gestione caso con una sola riga di subplot\n",
        "if len(unique_track_names) == 1:\n",
        "    axes = np.expand_dims(axes, axis=0)\n",
        "\n",
        "# Plot degli spettrogrammi\n",
        "for i, track_name in enumerate(unique_track_names):\n",
        "    # Seleziona i dati input e restored per la traccia corrente\n",
        "    input_spec_data = next((item for item in all_spectrograms_db_data if item['name'] == f'\"{track_name}\" input'), None)\n",
        "    restored_spec_data = next((item for item in all_spectrograms_db_data if item['name'] == f'\"{track_name}\" restored'), None)\n",
        "\n",
        "    if input_spec_data and restored_spec_data:\n",
        "        # -------------------------\n",
        "        # Spettrogramma input\n",
        "        # -------------------------\n",
        "        ax_input = axes[i, 0]\n",
        "        librosa.display.specshow(input_spec_data['spectrogram_db'], sr=input_spec_data['sr'],\n",
        "                                 x_axis='time', y_axis='mel', vmin=global_vmin, vmax=global_vmax, ax=ax_input)\n",
        "        fig.colorbar(ax_input.collections[0], format='%+2.0f dB', ax=ax_input)\n",
        "        ax_input.set_title(input_spec_data['name'])\n",
        "        ax_input.set_xlabel('time (s)')\n",
        "        ax_input.set_ylabel('frequency (Hz)')\n",
        "\n",
        "        # -------------------------\n",
        "        # Spettrogramma restored\n",
        "        # -------------------------\n",
        "        ax_restored = axes[i, 1]\n",
        "        librosa.display.specshow(restored_spec_data['spectrogram_db'], sr=restored_spec_data['sr'],\n",
        "                                 x_axis='time', y_axis='mel', vmin=global_vmin, vmax=global_vmax, ax=ax_restored)\n",
        "        fig.colorbar(ax_restored.collections[0], format='%+2.0f dB', ax=ax_restored)\n",
        "        ax_restored.set_title(restored_spec_data['name'])\n",
        "        ax_restored.set_xlabel('time (s)')\n",
        "        ax_restored.set_ylabel('frequency (Hz)')\n",
        "    else:\n",
        "        print(f\"Warning: Dati spettrogramma non trovati per la traccia {track_name}\")\n",
        "\n",
        "# Ottimizza il layout e mostra la figura\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9w5MgcPdZCE",
        "outputId": "f59edb5a-6111-48cf-eebd-0573cf281861"
      },
      "outputs": [],
      "source": [
        "# 6. RICOSTRUZIONE DELL'AUDIO DA TUTTE LE TRACCE PULITE\n",
        "\n",
        "# Estrai tutte le tracce audio pulite\n",
        "all_cleaned_audio_data = [track['audio'] for track in cleaned_tracks_data]\n",
        "\n",
        "# Trova la lunghezza massima tra tutte le tracce\n",
        "max_length = max(len(audio) for audio in all_cleaned_audio_data)\n",
        "\n",
        "# Inizializza un array di zeri con la lunghezza massima e tipo float32\n",
        "reconstructed_audio = np.zeros(max_length, dtype=np.float32)\n",
        "\n",
        "# Itera attraverso tutte le tracce pulite, effettua il padding e somma\n",
        "for audio_track in all_cleaned_audio_data:\n",
        "    # Aggiungi zeri alla fine della traccia per farla arrivare a max_length\n",
        "    padded_track = np.pad(audio_track, (0, max_length - len(audio_track)), 'constant')\n",
        "    # Somma la traccia al mix ricostruito\n",
        "    reconstructed_audio += padded_track\n",
        "\n",
        "print(f\"Audio ricomposto creato con successo.\")\n",
        "print(f\"Durata: {len(reconstructed_audio)} campioni ({len(reconstructed_audio)/current_sr:.2f} secondi).\")\n",
        "print(f\"Frequenza di campionamento utilizzata: {current_sr} Hz.\")\n",
        "\n",
        "# -------------------------\n",
        "# Salva l'audio ricomposto in un file WAV\n",
        "# -------------------------\n",
        "output_reconstructed_file = '/content/reconstructed_audio.wav'\n",
        "\n",
        "# Se vuoi usare Pedalboard o sf.write, qui usiamo soundfile (sf)\n",
        "import soundfile as sf\n",
        "sf.write(output_reconstructed_file, reconstructed_audio, current_sr)\n",
        "\n",
        "print(f\"Audio ricomposto salvato come: {output_reconstructed_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "aGlNWIcFVsKK",
        "outputId": "b93d8978-751f-4e93-ec99-394a19fc6936"
      },
      "outputs": [],
      "source": [
        "#7. RIPRODUZIONE DELLA VERSIONE ORIGINALE E DELLE RESTAURATE\n",
        "\n",
        "# Audio originale\n",
        "print(\"Riproduzione dell'audio originale:\")\n",
        "print(f\"Durata: {len(y)/sr:.2f} secondi, Frequenza di campionamento: {sr} Hz\")\n",
        "display(Audio(y, rate=sr))\n",
        "\n",
        "# Audio migliorato senza separazione in tracce\n",
        "print(\"Riproduzione dell'audio migliorato (senza separazione in tracce):\")\n",
        "print(f\"Durata: {len(effected_audio)/current_sr:.2f} secondi, Frequenza di campionamento: {current_sr} Hz\")\n",
        "display(Audio(effected_audio, rate=current_sr))\n",
        "\n",
        "# Audio ricomposto sommando tutte le tracce pulite\n",
        "print(\"Riproduzione dell'audio migliorato dividendo in tracce e ricomponendo:\")\n",
        "print(f\"Durata: {len(reconstructed_audio)/current_sr:.2f} secondi, Frequenza di campionamento: {current_sr} Hz\")\n",
        "display(Audio(reconstructed_audio, rate=current_sr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "heEVaxdCb-91",
        "outputId": "27a0da6a-cbee-4aa4-bdfc-51b3cb34391f"
      },
      "outputs": [],
      "source": [
        "#8. SPETTROGRAMMI\n",
        "\n",
        "# Assumendo che y1 = y sia l'audio originale\n",
        "y1 = y\n",
        "\n",
        "# Calcola gli spettrogrammi Mel\n",
        "S_input = librosa.feature.melspectrogram(y=y1, sr=current_sr)\n",
        "S_direct = librosa.feature.melspectrogram(y=effected_audio, sr=current_sr)\n",
        "S_stemwise = librosa.feature.melspectrogram(y=reconstructed_audio, sr=current_sr)  # <-- stem-wise restoration\n",
        "\n",
        "# Converti in decibel\n",
        "S_db_input = librosa.power_to_db(S_input, ref=np.max)\n",
        "S_db_direct = librosa.power_to_db(S_direct, ref=np.max)\n",
        "S_db_stemwise = librosa.power_to_db(S_stemwise, ref=np.max)\n",
        "\n",
        "# Trova min e max globali per la scala colori uniforme\n",
        "vmin = min(S_db_input.min(), S_db_direct.min(), S_db_stemwise.min())\n",
        "vmax = max(S_db_input.max(), S_db_direct.max(), S_db_stemwise.max())\n",
        "\n",
        "# Crea la figura con 3 subplot\n",
        "plt.figure(figsize=(18, 6))\n",
        "\n",
        "# Subplot 1: input audio\n",
        "plt.subplot(1, 3, 1)\n",
        "librosa.display.specshow(S_db_input, sr=current_sr, x_axis='time', y_axis='mel', vmin=vmin, vmax=vmax)\n",
        "plt.colorbar(format='%+2.0f dB')\n",
        "plt.title('input audio')\n",
        "plt.xlabel('time (s)')\n",
        "plt.ylabel('frequency (Hz)')\n",
        "\n",
        "# Subplot 2: direct restoration\n",
        "plt.subplot(1, 3, 2)\n",
        "librosa.display.specshow(S_db_direct, sr=current_sr, x_axis='time', y_axis='mel', vmin=vmin, vmax=vmax)\n",
        "plt.colorbar(format='%+2.0f dB')\n",
        "plt.title('direct restoration')\n",
        "plt.xlabel('time (s)')\n",
        "plt.ylabel('frequency (Hz)')\n",
        "\n",
        "# Subplot 3: stem-wise restoration\n",
        "plt.subplot(1, 3, 3)\n",
        "librosa.display.specshow(S_db_stemwise, sr=current_sr, x_axis='time', y_axis='mel', vmin=vmin, vmax=vmax)\n",
        "plt.colorbar(format='%+2.0f dB')\n",
        "plt.title('stem-wise restoration')\n",
        "plt.xlabel('time (s)')\n",
        "plt.ylabel('frequency (Hz)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Spettrogrammi generati e visualizzati per input audio, direct restoration e stem-wise restoration con la stessa scala di colori.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vjOT6I8Z94k",
        "outputId": "542b5b60-e568-4dac-c15a-a792e28b9ef4"
      },
      "outputs": [],
      "source": [
        "# 9. ANALISI DEL 25° PERCENTILE DEGLI SPETTROGRAMMI\n",
        "\n",
        "# Calcola il 25° percentile (energia a bassa ampiezza) per ciascun spettrogramma\n",
        "\n",
        "# Spettrogramma originale\n",
        "percentile_25_original = np.percentile(S_db_input, 25)\n",
        "\n",
        "# Spettrogramma migliorato senza dividere in tracce (direct restoration)\n",
        "percentile_25_direct = np.percentile(S_db_direct, 25)\n",
        "\n",
        "# Spettrogramma migliorato dividendo in tracce (hybrid restoration)\n",
        "percentile_25_stemwise = np.percentile(S_db_stemwise, 25)\n",
        "\n",
        "# Stampa i valori calcolati\n",
        "print(f\"25° percentile dello spettrogramma input audio: {percentile_25_original:.2f} dB\")\n",
        "print(f\"25° percentile dello spettrogramma direct restoration: {percentile_25_direct:.2f} dB\")\n",
        "print(f\"25° percentile dello spettrogramma stem-wise restoration: {percentile_25_stemwise:.2f} dB\\n\")\n",
        "\n",
        "# Confronto per determinare quale metodo riduce maggiormente il rumore a bassa ampiezza\n",
        "if percentile_25_stemwise < percentile_25_original and percentile_25_stemwise < percentile_25_direct:\n",
        "    print(\"Il 25° percentile è più basso con la stem-wise restoration, quindi é questo il caso in cui si ha una maggiore riduzione del rumore.\")\n",
        "elif percentile_25_direct < percentile_25_original and percentile_25_direct < percentile_25_stemwise:\n",
        "    print(\"Il 25° percentile è più basso con la direct restoration, quindi é questo il caso in cui si ha una  maggiore riduzione del rumore.\")\n",
        "else:\n",
        "    print(\"Il 25° percentile più basso è nell'audio input: le versioni migliorate non hanno ridotto il rumore a bassa ampiezza.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
